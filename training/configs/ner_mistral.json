{
  "job_name": "ner_mistral",
  "model_name": "mistralai/Mistral-7B-Instruct-v0.1",
  "tokenizer_kwargs": {
    "padding_side": "right",
    "add_eos_token": true,
    "add_bos_token": true
  },
  "tokenizer_use_eos_token": true,
  "dataset_name": "textminr/squad_v2",
  "dataset_context_col": "context",
  "dataset_instruction_col": "question",
  "dataset_response_col": "answer",
  "seq_length": 1024,
  "use_peft": true,
  "load_in_4bit": true,
  "lora_r": 16,
  "lora_alpha": 16,
  "target_modules": [
    "q_proj",
    "k_proj",
    "v_proj",
    "o_proj",
    "gate_proj",
    "up_proj",
    "down_proj"
  ],
  "batch_size": 3,
  "gradient_accumulation_steps": 3,
  "warmup_steps": 100,
  "do_eval": true,
  "eval_strategy": "steps",
  "eval_steps": 500,
  "report_to_wandb": true,
  "wandb_project": "ner_mistral_qlora",
  "push_to_hub": true,
  "hub_model_id": "textminr/ner-mistral-7b"
}